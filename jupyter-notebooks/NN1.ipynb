{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m weights \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     [\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m],\n\u001b[1;32m     11\u001b[0m     [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.91\u001b[39m, \u001b[38;5;241m0.26\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m],\n\u001b[1;32m     12\u001b[0m     [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.26\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.27\u001b[39m, \u001b[38;5;241m0.17\u001b[39m, \u001b[38;5;241m0.87\u001b[39m]\n\u001b[1;32m     13\u001b[0m ] \n\u001b[1;32m     15\u001b[0m biases \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m, \u001b[38;5;241m0.5\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m biases\n\u001b[1;32m     18\u001b[0m layer_outputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/nnfs/core.py:22\u001b[0m, in \u001b[0;36minit.<locals>.dot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m orig_dot(\u001b[38;5;241m*\u001b[39m[\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [\n",
    "    [1.0, 2.0, 3.0, 2.5], \n",
    "    [2.0, 5.0, -1.0, 2.0],\n",
    "    [-1.5, 2.7, 3.3, -0.8]\n",
    "] \n",
    "\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1.0],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "] \n",
    "\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "layer_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nnfs in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.5.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nnfs) (1.26.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nnfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnfs.datasets import spiral_data\n",
    "import nnfs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnfs.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "class Activation_ReLU:\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "class Activation_Softmax:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "        self.output = probabilities\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "        \n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            single_output = np.array(single_output).reshape(-1, 1)\n",
    "            print(single_output)\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "            print(jacobian_matrix)\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)\n",
    "\n",
    "class Loss:\n",
    "\n",
    "    def calculate(self, output, y):\n",
    "\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                axis=1\n",
    "            )\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "    \n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "        \n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        self.dinputs = self.dinputs/samples\n",
    "\n",
    "# final layer of neural network, combining classification layer and loss function calculation for simplification purposes\n",
    "# takes as its input the output of the second dense layer (is this a matrix? why?)\n",
    "# outputs a classification based on output of second dense layer and then loss is calculated based on this classification\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # takes as input, the output of the second layer and creates a classification\n",
    "    # then calculates loss based on how wrong this classification is\n",
    "    def forward(self, inputs, y_true):\n",
    "\n",
    "        self.activation.forward(inputs)\n",
    "        self.output = self.activation.output\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "    \n",
    "    # final output is loss for classifcation of each batch (or is it called sample?) and input is all outputs of second dense layer\n",
    "    # so gradients is partial derivate of loss with respect to every input from second dense layer\n",
    "    # partial derivative = predicted probabilities - ground truth probabilities\n",
    "    def backward(self, dvalues , y_true) -> None:\n",
    "\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        # normalises gradient \n",
    "        # if we had n samples in the predicted probabilities matrix then we subtract n from it in total, as from each sample we subtract 1 (the value of the ground truth)\n",
    "        # so to normalise gradient we have to divide it by n\n",
    "        #gradient_matrix_row[i] / n is normalised \n",
    "        self.dinputs = self.dinputs/samples\n",
    "\n",
    "class Optimizer_SGD:\n",
    "\n",
    "    def __init__(self, learning_rate=1.0, decay=0, momentum=0):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def pre_udpate_params(self):\n",
    "\n",
    "        # before each update, decay learning rate by one iteration\n",
    "\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1 / (1+self.decay*self.iterations))\n",
    "\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        if self.momentum:\n",
    "\n",
    "        # SDG with momentum:\n",
    "        # parameters = parameters + ( (momentum * previous updates) - (learning rate * parameter gradients) )\n",
    "        \n",
    "        # update contains a portion of the gradient from preceding steps and only a portion o the current gradient\n",
    "        # together these portions form the update to our parameters\n",
    "        # the larger the momentum, the slower the update can change the direction\n",
    "\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "\n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "\n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "        \n",
    "        else:   \n",
    "            # vanilla SDG: parameters = parameters - (learning_rate * parameter gradient)\n",
    "            weight_updates = -self.current_learning_rate * layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "    def post_udpate_params(self):\n",
    "        \n",
    "        self.iterations += 1\n",
    "\n",
    "class Optimizer_Adagrad:\n",
    "\n",
    "    def __init__(self, learning_rate=1.0, decay=0, epsilon = 1e-7):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def pre_udpate_params(self):\n",
    "\n",
    "        # before each update, decay learning rate by one iteration\n",
    "\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1 / (1+self.decay*self.iterations))\n",
    "\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # keep cache of squared gradients\n",
    "        # objective is to normalize parameter updates, the bigger the sum of the updates, in positive or negative direction, the smaller updates are made further in training\n",
    "        # let's less frequently updated parameters keep up with training, effectively using more neurons for training\n",
    "\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # larger gradient magnitude, means larger parameter update so cache for that increases\n",
    "        # this means next updates will be smaller\n",
    "        layer.weight_cache += layer.dweights**2\n",
    "        layer.bias_cache += layer.dbiases**2\n",
    "\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache)+self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache)+self.epsilon)\n",
    "\n",
    "    def post_udpate_params(self):\n",
    "        \n",
    "        self.iterations += 1\n",
    "\n",
    "class Optimizer_RMSprop:\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, decay=0, epsilon = 1e-7, rho=0.9):\n",
    "        \n",
    "        self.learning_rate = learning_rate \n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "\n",
    "    def pre_udpate_params(self):\n",
    "\n",
    "        # before each update, decay learning rate by one iteration\n",
    "\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1 / (1+self.decay*self.iterations))\n",
    "\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # RMSProp uses a moving average of the cache so that the cache contents move with time and learning does not stall\n",
    "        # Each cache updates retains a part of the cache and updates it with a fraction of the new squared gradients\n",
    "        # the hyper-parameter rho decides how much of old cache we keep and how much new gradients change cache\n",
    "\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        layer.weight_cache = self.rho * layer.weight_cache + (1-self.rho) * layer.dweights**2\n",
    "        layer.bias_cache = self.rho * layer.bias_cache + (1-self.rho) * layer.dbiases**2\n",
    "\n",
    "        # like with Adagrad, since we're dividing by cache, slows down updates to parameters that have already updated a lot\n",
    "\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache)+self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache)+self.epsilon)\n",
    "\n",
    "    def post_udpate_params(self):\n",
    "        \n",
    "        self.iterations += 1\n",
    "\n",
    "class Optimizer_Adam:\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, decay=0, epsilon = 1e-7, beta_1=0.9, beta_2=0.999):\n",
    "        \n",
    "        self.learning_rate = learning_rate \n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "\n",
    "    def pre_udpate_params(self):\n",
    "\n",
    "        # before each update, decay learning rate by one iteration\n",
    "\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1 / (1+self.decay*self.iterations))\n",
    "\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # Adam uses learning decay, updates parameters with paramter momentums instead of gradients, a cache and a bias correction mechanism for initial iterations\n",
    "\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # instead of applying current parameter gradients to cache, we apply momentums\n",
    "        # momentum has part of previous parameter momentums and part of current gradient, beta_1 decides how much of each\n",
    "\n",
    "        layer.weight_momentums = self.beta_1 * layer.weight_momentums + (1 - self.beta_1) * layer.dweights\n",
    "        layer.bias_momentums = self.beta_1 * layer.bias_momentums + (1 - self.beta_1) * layer.dbiases\n",
    "\n",
    "        # with previous caches and momentums, the initial iterations are impacted by the zero-valued start before they warm up with the initial steps\n",
    "        # Adam fixes this, by dividing momentums and caches by (1-beta^step) \n",
    "        # so initialiy we are artificially increasing momentum and cache to speed up training in initial stages\n",
    "\n",
    "        weight_momentums_corrected = layer.weight_momentums / (1-self.beta_1 ** (self.iterations+1))\n",
    "        bias_momentums_corrected = layer.bias_momentums / (1-self.beta_1 ** (self.iterations+1))\n",
    "\n",
    "        #cache updates work in the same way as for Adagrad. cache is updated with portion of old cache and portion of current gradients, portion decided by beta_2 hyperparameter\n",
    "        layer.weight_cache = self.beta_2 * layer.weight_cache + (1-self.beta_2) * layer.dweights**2\n",
    "        layer.bias_cache = self.beta_2 * layer.bias_cache + (1-self.beta_2) * layer.dbiases**2\n",
    "\n",
    "\n",
    "        # correct cache with initial bias correcting mechanism\n",
    "        weight_cache_corrected = layer.weight_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "        bias_cache_corrected = layer.bias_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "\n",
    "        # learning rate multiplied by parameter momentums instead of gradients and then cache normalisation is as usual\n",
    "        # like with Adagrad, since we're dividing by cache, slows down updates to parameters that have already updated a lot\n",
    "        layer.weights += -self.current_learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected)+self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected)+self.epsilon)\n",
    "\n",
    "    def post_udpate_params(self):\n",
    "        \n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8, 0.7])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = np.array([0, 1])\n",
    "pred = np.array([[0.8, 0.2], [0.3, 0.7]])\n",
    "samples = len(pred)\n",
    "pred_clipped = np.clip(pred, 1e-7, 1-1e-7)\n",
    "if len(true.shape) == 1:\n",
    "    correct_confidences = pred_clipped[\n",
    "                    range(samples),\n",
    "                    true]       \n",
    "correct_confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = spiral_data(samples=100, classes=3)\n",
    "plt.scatter(X[:,0], X[:,1]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.260,  loss: 1.099, lr: 0.02\n",
      "epoch: 1000, acc: 0.770,  loss: 0.498, lr: 0.018183471224656786\n",
      "epoch: 2000, acc: 0.810,  loss: 0.361, lr: 0.016668055671305942\n",
      "epoch: 3000, acc: 0.883,  loss: 0.291, lr: 0.015385798907608278\n",
      "epoch: 4000, acc: 0.923,  loss: 0.220, lr: 0.014286734766769053\n",
      "epoch: 5000, acc: 0.943,  loss: 0.185, lr: 0.013334222281485434\n",
      "epoch: 6000, acc: 0.947,  loss: 0.165, lr: 0.01250078129883118\n",
      "epoch: 7000, acc: 0.950,  loss: 0.151, lr: 0.011765397964586153\n",
      "epoch: 8000, acc: 0.947,  loss: 0.144, lr: 0.011111728429357186\n",
      "epoch: 9000, acc: 0.947,  loss: 0.135, lr: 0.010526869835254487\n",
      "epoch: 10000, acc: 0.943,  loss: 0.126, lr: 0.010000500025001252\n"
     ]
    }
   ],
   "source": [
    "optimizer = Optimizer_RMSprop(learning_rate=0.02, decay=1e-4, rho=0.999)\n",
    "dense1 = Layer_Dense(2,64)\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(64,3)\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "for epoch in range(10001):\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    if not epoch % 1000:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {accuracy:.3f}, ' +\n",
    "              f' loss: {loss:.3f}, ' +\n",
    "              f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    optimizer.pre_udpate_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_udpate_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.4922287\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.56910783 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.8005913  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.7091483  0.         0.         0.         2.5282142\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         2.2669609  0.         0.         0.         1.9854008\n",
      "  0.         0.         0.         1.4699218  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.588457\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.5111399  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.7836837  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.74402994 0.         0.         0.         2.6024823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         2.345981   0.         0.         0.         2.005455\n",
      "  0.         0.         0.         1.5581946  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.64456606\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.45794    0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.7922522  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.7229837  0.         0.         0.         2.6908104\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         2.4128892  0.         0.         0.         1.9983513\n",
      "  0.         0.         0.         1.6271406  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.7880382\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.46817866 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.6752243  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.9812056  0.         0.         0.         2.577196\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         2.426897   0.         0.         0.         2.1219137\n",
      "  0.         0.         0.         1.6716738  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.77234614\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.35241145 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.796923   0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.7083892  0.         0.         0.         2.8556986\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         2.548482   0.         0.         0.         1.9973145\n",
      "  0.         0.         0.         1.7700784  0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "activation1.forward(dense1.output)\n",
    "print(activation1.output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n",
      "[ True False  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_outputs = np.array([[0.7, 0.2, 0.1],\n",
    "                            [0.5, 0.1, 0.4],\n",
    "                            [0.02, 0.9, 0.08]])\n",
    "class_targets = np.array([0, 1, 1])\n",
    "\n",
    "predictions = np.argmax(softmax_outputs, axis=1)\n",
    "print(predictions)\n",
    "print(predictions==class_targets)\n",
    "accuracy = np.mean(predictions==class_targets)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3,4],\n",
    "              [5,6,7,8],\n",
    "              [9,10,11,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  9],\n",
       "       [ 2,  6, 10],\n",
       "       [ 3,  7, 11],\n",
       "       [ 4,  8, 12]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 ]\n",
      " [0.2 ]\n",
      " [0.31]]\n",
      "[[ 0.09   -0.02   -0.031 ]\n",
      " [-0.02    0.16   -0.062 ]\n",
      " [-0.031  -0.062   0.2139]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m dvalues \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.31\u001b[39m],\n\u001b[1;32m      3\u001b[0m            [\u001b[38;5;241m0.14\u001b[39m, \u001b[38;5;241m0.42\u001b[39m, \u001b[38;5;241m0.31\u001b[39m],\n\u001b[1;32m      4\u001b[0m            [\u001b[38;5;241m0.11\u001b[39m, \u001b[38;5;241m0.22\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]]\n\u001b[1;32m      5\u001b[0m soft\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.31\u001b[39m],\n\u001b[1;32m      6\u001b[0m            [\u001b[38;5;241m0.14\u001b[39m, \u001b[38;5;241m0.42\u001b[39m, \u001b[38;5;241m0.31\u001b[39m],\n\u001b[1;32m      7\u001b[0m            [\u001b[38;5;241m0.11\u001b[39m, \u001b[38;5;241m0.22\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]]\n\u001b[0;32m----> 8\u001b[0m \u001b[43msoft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 44\u001b[0m, in \u001b[0;36mActivation_Softmax.backward\u001b[0;34m(self, dvalues)\u001b[0m\n\u001b[1;32m     42\u001b[0m jacobian_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiagflat(single_output) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(single_output, single_output\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(jacobian_matrix)\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdinputs[index] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjacobian_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_dvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/nnfs/core.py:22\u001b[0m, in \u001b[0;36minit.<locals>.dot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m orig_dot(\u001b[38;5;241m*\u001b[39m[\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "soft = Activation_Softmax()\n",
    "dvalues = [[0.1, 0.2, 0.31],\n",
    "           [0.14, 0.42, 0.31],\n",
    "           [0.11, 0.22, 0.1]]\n",
    "soft.output = [[0.1, 0.2, 0.31],\n",
    "           [0.14, 0.42, 0.31],\n",
    "           [0.11, 0.22, 0.1]]\n",
    "soft.backward(dvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1 ],\n",
       "       [0.2 ],\n",
       "       [0.2 ],\n",
       "       [0.1 ],\n",
       "       [0.31],\n",
       "       [0.4 ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_output = np.array([[0.1, 0.2],\n",
    "                [0.2, 0.1],\n",
    "                [0.31, 0.4]])\n",
    "single_output.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(single_output)\n",
    "len(single_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2,  0.1, -0.3],\n",
       "       [ 0.3, -0.4,  0.1],\n",
       "       [ 0.8, -0.9,  0.1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinputs = np.array([[0.2, 0.1, 0.7],\n",
    "                    [0.3, 0.6, 0.1],\n",
    "                    [0.8, 0.1, 0.1]])\n",
    "y_true = np.array([[0,0,1],\n",
    "                    [0,1,0],\n",
    "                    [0,1,0]])\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "dinputs[range(3), y_true] -= 1\n",
    "dinputs = dinputs \n",
    "dinputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
